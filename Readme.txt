CCB是处理hdfs中数据的程序
部署在5.0.95.85的/project/song/hdfstoHbase中，邱总要求日志一天产生一个，程序中的log4j.properties定义日志一天产生一个，日志目录在/project/song/log/hdfsToHbase中，
当天的日志后边不带有日志，每天结束后变为带日期的日志

此程序为五分钟执行一次，此设定在54.0.95.85中执行crontab -l即可查看，第一行设置此程序五分钟执行一次，
第二行为Spark统计程序五分钟执行一次，第三行为十五分钟统计一次，第四行为一个小时，第五行为1天，分别统计五分钟，十五分钟
一个小时，一天各devid所有指标项的平均值，最大值，最小值

打jar包是选中项目右键Export-->Runnable JAR file,在Launch configuration中选中所选项目的主类，下边为导出的路径，导出后为一个指定
名字的jar包，还有一个jar包名_lib的所使用jar包的文件夹，部署时此文件夹不用每次都上传，只要存在就可以了

还有就是上次开会的那个问题，如果Flume 宕掉了，重传时统计信息无法统计之前的数据，
邱总上次提出的想法是每次hdfs日志解析时把文件里包含的所有时间都统计每隔五分钟，15分钟，1个小时，1天的，但这样如果是7天数据一起传来
，花费的时间太长，不可行，这个我已经跟邱总说了，他说是都在想想看解决方法。

我的想法从两方面入手，
一方面尽最大可能尽早知道Flume宕机，就像Ambari的心跳机制，mysql的Bean表中会每次解析hdfs日志时更新最新的数据，可以每次统计完之后查看哪台设备没有传过来数据，如果这个设备连续一个小时没有数据传来就
告警，认定为Flume死掉，发出告警
另一方面是在数据处理端处理我觉得在hdfs处理数据时进行统计需要的时间太久，在统计画图的界面上可以加一个按钮，因为界面关注的显示一天的
数据是显示的按小时统计的结果，统计下来可能需要十几分钟。按小时统计一个月的数据需要的时间会差不多三倍。这样的时间在后台跑，然后统计完成
之后再对应的统计任务后的标志位修改，就像hietl传数据时的机制。(仅供参考，我这种方法的代码量会很大)

Projrct为spark的统计程序，放到集群上之前需要把com.CCB.Spark.util.SparkUtil中的static中的第一行注释掉，启用第二行，因local表示本地模式，window开发做测试可以用这个
，就是在本机上运行的，只要有spark的jar包就可以运行，没有local表示集群模式